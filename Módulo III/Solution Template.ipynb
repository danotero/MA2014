{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution Template\n",
    "\n",
    "Use this notebook as a guide to implement your solution. Keep in mind that some cells should remain as they are so that you code works properly, for instance, the following cell in which the required libraries are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Import the libraries you need in this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localization\n",
    "\n",
    "Hidden Markov Models (HMM) are used in a wide variety of applications such as speech recognition, part-of-speech tagging, machine traslation, handwriting recognition and many more. In this section we will see how HMM can be employed to infer the position of a robot in a static enviroment.\n",
    "\n",
    "Let us represent the enviroment in which the robot roams around by a grid. Each square of the grid is either free or occupied, in which case we are talking about a position that the robot can not visit. Let $X_k$ be the position of the robot at time $t_k$. Given the latter, all the possible states of $X_k$ are the free spots of the grid: $S\\{s_1,s_2,\\dots,s_n\\}$, where $n$ is the number of free squares. Speaking of \"free squares,\" suppose we do not know where the robot is, so $P(X_0)=1/n$, $\\forall s_i\\in S$. Also, let $\\text{neighnors}(s)$ be the set of empty squares adjacent to $s$ and let $N(s)$ be the size of this set. Then, the transition model of a robot that moves to any adjacent and empty square with equal probability is given by\n",
    "\n",
    "$$\n",
    "P(X_{k+1}=s_j|X_k=s_i)=T_{ij}=\n",
    "\\begin{cases}\n",
    "\\frac{1}{N(s_i)}~, & s_j\\in \\text{neighbors}(s_i)\\\\\n",
    "0, & s_j\\notin \\text{neighbors}(s_i)\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "As it was mentioned, the robot will try to know where it is located given a set of observations. In this case, the robot is equipped with four sensors that indicate if there is an obstacle or not in a particular direction. We will assume all the possible directions are North (N), East (E), West (W) and South (S). Further, there is a sensor error rate $\\epsilon$ and errors occur independently in the four sensor directions. For instance, the probability of getting all four measurements right is $(1-\\epsilon)^4$, the probability of getting them all wrong is $\\epsilon^4$. Given this, we have that there are 16 possible measurements for $E_k$ at a given time $t_k$. Also, let $d_{ik}$ be the discrepancy: the number of bits that are different from the true bits for the square $s_i$. Then, the probability that a robot in square $s_i$ would get a reading $e_k$ is equal to\n",
    "\n",
    "$$\n",
    "P(E_k=e_k|X_k=s_i)=O_{e_k,ii}=(1-\\epsilon)^{4-d_{~ik}}~\\epsilon^{~d_{~ik}}.\n",
    "$$\n",
    "\n",
    "For instance, the probability that a square with obstacles to the North and South would produce a reading (N,S,E) is equal to $(1-\\epsilon)^3~\\epsilon$.\n",
    "\n",
    "Now that we know how to define the transition and sensor models we can carry out different types of inference: we can estimate a location given a set of measurements doing filtering; we can use smoothing to infer a past location given some observations; or we can use the Viterbi algorithm and obtain the most likely path that the robot took and that produced a given set of sensor values.\n",
    "\n",
    "<img src=\"robot.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "Your mission is to carry out these three types of inference. In particular, for both filtering and smoothing, instead of using something like the figures shown above, use heatmaps in which the color changes depending on the probability of finding the robot at a certain square given a set of measurements. For the most likely path highlight the squares associated to said path. Keep in mind that you will have to simulate the random behavior of the sensors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Model\n",
    "\n",
    "Let us define some matrices. Say we have $k$ possible states: $S=\\{s_1,s_2\\dots,s_k\\}$. Then, the **transition matrix** is a $k\\times k$ matrix in which $T_{ij} = P(X_{k+1}=s_j|X_{k}=s_i)$. In this case, each state is a position that can be occupied by the robot, or in other words, a free cell. Notice that in the map there are a total of 42 free cells, which means that the system has 42 possible states. The latter implies that the transitions matrix is a $42\\times42$ matrix.\n",
    "\n",
    "Use the following cell to define a dictionary that will contain all the possible states of the system. Remember that each state is a location that can be stored as a tuple. Pick the origin as the upper left corner of the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Store the states of the system in a dictionary following this format:\n",
    "S = {0: (0, 0), 1: (1, 0), ..., 41: (15, 3)}\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the states, write a function that receives as input the dictionary that you just defined, and returns a dictionary in which each element is a state with a list of its corresponding neighbors. This funtion will be useful for implementing both the transition and sensor models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbors_states(states, location=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a dictionary of states with lists of neighboring states or locations.\n",
    "\n",
    "    Parameters:\n",
    "    - states (dict): A dictionary mapping state names to 2D positions.\n",
    "    - location (bool): If True, returns a dictionary with each state and its neighboring locations.\n",
    "                      If False, returns a dictionary with each state and its neighboring states.\n",
    "\n",
    "    Returns:\n",
    "    - states_neighbors (dict): A dictionary where each element is a state with a list of its neighbors\n",
    "                               (either states or locations based on the 'location' parameter).\n",
    "    \"\"\"\n",
    "    \n",
    "    states_neighbors = {}\n",
    "    \n",
    "    \"INSERT YOUR CODE HERE\"\n",
    "                    \n",
    "    return states_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that computes the transition matrix. The function receives as input the dictionary that contains the states of the system and returns the transition matrix as a `Numpy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(states):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the transition matrix based on a dictionary containing the states of the system.\n",
    "\n",
    "    Parameters:\n",
    "    - states (dict): A dictionary mapping state names to 2D positions.\n",
    "\n",
    "    Returns:\n",
    "    - t_matrix (numpy.ndarray): Transition matrix representing the probabilities of transitioning \n",
    "                                from one state to another. The matrix is of size 42x42.\n",
    "    \"\"\"\n",
    "    \n",
    "    t_matrix = np.zeros((42, 42))\n",
    "    \n",
    "    \"INSERT YOUR CODE HERE\"\n",
    "                    \n",
    "    return t_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Model\n",
    "\n",
    "At this point you know that there are 16 possible measurements for $E_k$ at a given time $t_k$. For each measurement you will need to define a matrix that stores the probabilities of getting a reading $e_k$ given that the robot is at the location $s_i$:\n",
    "\n",
    "$$\n",
    "P(E_k=e_k|X_k=s_i)=O_{e_k,ii}=(1-\\epsilon)^{4-d_{~ik}}~\\epsilon^{~d_{~ik}}.\n",
    "$$\n",
    "\n",
    "In the following cell, write code for computing the matrices of the sensor model. Notice that you will have to define an error rate $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def expected_measurements(states):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate expected measurements for each state based on their neighbors.\n",
    "\n",
    "    Parameters:\n",
    "    - states (dict): A dictionary mapping state names to 2D positions.\n",
    "\n",
    "    Returns:\n",
    "    - measurements (dict): A dictionary mapping state names to binary representations \n",
    "                          of expected measurements (based on neighboring positions).\n",
    "    \"\"\"\n",
    "    \n",
    "    measurements = {}\n",
    "    \n",
    "    \"INSERT YOUR CODE HERE\"\n",
    "    \n",
    "    return measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_discrepancy(measure_1, measure_2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the discrepancy between two binary measurements.\n",
    "\n",
    "    Parameters:\n",
    "    - measure_1 (str): Binary representation of the first measurement.\n",
    "    - measure_2 (str): Binary representation of the second measurement.\n",
    "\n",
    "    Returns:\n",
    "    - discrepancy (int): The number of differing bits between the two binary measurements.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"INSERT YOUR CODE HERE\"\n",
    "    \n",
    "    return discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation_matrix(epsilon, measure, measurements):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the observation matrix based on a given binary measurement and a set of expected measurements.\n",
    "\n",
    "    Parameters:\n",
    "    - epsilon (float): Probability of measurement error.\n",
    "    - measure (str): Binary representation of the actual measurement.\n",
    "    - measurements (numpy.ndarray): Array containing binary representations of expected measurements \n",
    "                                   for each state in the system.\n",
    "\n",
    "    Returns:\n",
    "    - o_matrix (numpy.ndarray): Observation matrix representing the probabilities of obtaining the \n",
    "                               actual measurement given the expected measurements. The matrix is of size 42x42.\n",
    "    \"\"\"\n",
    "    \n",
    "    o_matrix = np.zeros((42, 42))\n",
    "    \n",
    "    \"INSERT YOUR CODE HERE\"\n",
    "        \n",
    "    return o_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation_matrices(epsilon, states):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute a set of observation matrices for different binary measurements based on a given set of states.\n",
    "\n",
    "    Parameters:\n",
    "    - epsilon (float): Probability of measurement error.\n",
    "    - states (dict): A dictionary mapping state names to 2D positions.\n",
    "\n",
    "    Returns:\n",
    "    - o_matrices (dict): A dictionary where each key is a binary measurement, and each value is an observation matrix\n",
    "                        representing the probabilities of obtaining the actual measurement given the expected measurements.\n",
    "                        The matrices are of size 42x42.\n",
    "    \"\"\"\n",
    "    \n",
    "    o_matrices = {}\n",
    "    \n",
    "    \"INSERT YOUR CODE HERE\"\n",
    "    \n",
    "    return o_matrices    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the readings can be understood as binary numbers of four digits: `0000`, `0001`,..., `1111`. Regarding the order of the binary measurements, use this convention: `ESWN`; that is, if the robot has obstacles in both the North and East directions, then an error-free measurement should be the binary number `1001`. For convenience, store the \"observation matrices\" in a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Call the function observation_matrices ans store the dictionary it returns in the variable \"O\". The function\n",
    "should follow this type of format:\n",
    "\n",
    "O = {0000: Matrix of measurement 0000, ..., 1111: Matrix of measurement 1111}\n",
    "\"\"\"\n",
    "\n",
    "epsilon = 0.1\n",
    "\n",
    "O = observation_matrices(epsilon, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_measurements(state, states):\n",
    "    \n",
    "    \"\"\"\n",
    "    Simulate measurements from a robot based on the expected measurements and measurement error.\n",
    "\n",
    "    Parameters:\n",
    "    - state (str): The current state for which measurements are simulated.\n",
    "    - states (dict): A dictionary mapping state names to 2D positions.\n",
    "\n",
    "    Returns:\n",
    "    - measured (str): Simulated binary measurement obtained from the robot with measurement errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    measured = ''\n",
    "    \n",
    "    \"INSERT YOUR CODE HERE\"\n",
    "            \n",
    "    return measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_robot_walk(states, steps):\n",
    "    \n",
    "    \"\"\"\n",
    "    Simulate a random walk of a robot in a system of states with measurements at each step.\n",
    "\n",
    "    Parameters:\n",
    "    - states (dict): A dictionary mapping state names to 2D positions.\n",
    "    - steps (int): The number of steps in the random walk.\n",
    "\n",
    "    Returns:\n",
    "    - path (list): List of 2D positions representing the path taken by the robot during the random walk.\n",
    "    - evidence (list): List of simulated binary measurements obtained by the robot at each step.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"INSERT YOUR CODE HERE\"\n",
    "        \n",
    "    return path, evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "In this context, **filtering** can be used to get an idea of the robot's location given a set of measurements. As it was mentioned in class, this type of inference is the act of, given some evidence up to a time $t_k$, we want to infer what is the probability distribution of the state $X_k$: $P(X_k|E_{1:k}=e_{1:k})$. Provide the `filtering` function with some evidence, which is going to be a sequence of bynary numbers of four digits, and compute the probability distribution of the state of the system at time $t_k$. Notice that said distribution should be a vector of 42 components. Do not forget to take into account the stochastic nature of the measurement process.\n",
    "\n",
    "Before going any further, it is important to define first the probability distribution of the initial state $X_0$. Also, run the function `random_robot_walk` to get a a simulation of the random walk of the robot plus a set of measurements. Store this information in tha variables `path` and `E` accordingly. Do that in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"INSERT YOUR CODE HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell for defining the `filtering` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(E, O, T, X0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Perform filtering using the Forward algorithm to estimate the probability distribution \n",
    "    over states given a sequence of measurements.\n",
    "\n",
    "    Parameters:\n",
    "    - E (list): List of binary measurements obtained at each time step.\n",
    "    - O (dict): Dictionary of observation matrices for different binary measurements.\n",
    "    - T (numpy.ndarray): Transition matrix representing the probabilities of transitioning between states.\n",
    "    - X0 (numpy.ndarray): Initial probability distribution over states.\n",
    "\n",
    "    Returns:\n",
    "    - forward (numpy.ndarray): Estimated probability distribution over states after incorporating \n",
    "                               the sequence of measurements.\n",
    "    \"\"\"\n",
    "    \n",
    "    forward = X0\n",
    "    \n",
    "    for evidence in E:\n",
    "        forward = O[evidence] @ T.T @ forward\n",
    "        forward = forward / forward.sum()\n",
    "        \n",
    "    return forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize\n",
    "\n",
    "Visualize your results using a heatmap. The `seaborn` library might be very useful for this purpose. In order to do this, write a function that receives the vector $X_k$ and returns a heatmap of a $4\\times16$ matrix in which each entry is the probability that the robot is occupying the location associated to said entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_heatmap(state, states):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create and display a heatmap based on the probability distribution of the robot's location in the system.\n",
    "\n",
    "    Parameters:\n",
    "    - state (numpy.ndarray): Vector of 42 components where each entry is the probability of finding the robot \n",
    "                             at a certain location.\n",
    "    - states (dict): A dictionary mapping state names to 2D positions.\n",
    "\n",
    "    Note:\n",
    "    - The function does not return anything, it is designed to display the heatmap using matplotlib and seaborn.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"INSERT YOUR CODE HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_heatmap(filtering(E, O, T, X0), S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the contents of the variable `path`. If there is a reasonable amount of measurements as evidence, the probability of the last element should be the highest. Verify that by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing\n",
    "\n",
    "As for **smoothing**, we can use it to infer a past state given a set of measurements: that is, we wish to obtain $P(X_j|E_{1:k}=e_{1:k})$, $1\\leq j<k$. Supply some evidence and run the `smoothing` function. Check that what the functions returns makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(E, O, T, X0, k):\n",
    "    \n",
    "    \"\"\"\n",
    "    Perform smoothing using the Forward-Backward algorithm to estimate the probability distribution \n",
    "    over states given a sequence of measurements, incorporating both past and future evidence with respect\n",
    "    to step time k.\n",
    "\n",
    "    Parameters:\n",
    "    - E (list): List of binary measurements obtained at each time step.\n",
    "    - O (dict): Dictionary of observation matrices for different binary measurements.\n",
    "    - T (numpy.ndarray): Transition matrix representing the probabilities of transitioning between states.\n",
    "    - X0 (numpy.ndarray): Initial probability distribution over states.\n",
    "    - k (int): Time step at which to perform smoothing.\n",
    "\n",
    "    Returns:\n",
    "    - smooth (numpy.ndarray): Estimated probability distribution over states at time step k, \n",
    "                             considering both past and future evidence.\n",
    "    \"\"\"\n",
    "    \n",
    "    forward = filtering(E[:k], O, T, X0)\n",
    "    \n",
    "    backward = np.ones((T.shape[0],1))\n",
    "    \n",
    "    for evidence in E[-1:k-1:-1]:\n",
    "        backward = T @ O[evidence] @ backward\n",
    "    \n",
    "    smooth = forward * backward\n",
    "    smooth = smooth / smooth.sum()\n",
    "    \n",
    "    return smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_heatmap(smoothing(E, O, T, X0, 1), S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the contents of the `path` variable again. If there is a reasonable number of measurements as evidence, the probability of the kth element should be the highest. Check this by executing the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Likely Sequence of States\n",
    "\n",
    "Finally, for obtaining the most likely sequence that produced the given evidence, we need to compute\n",
    "\n",
    "$$\n",
    "\\max_{x_{1:k}}P(x_{1:k}|E_{1:k}=e_{1:k}).\n",
    "$$\n",
    "\n",
    "As it was mentioned in class, the most likely sequence is the one that has the highest probability, which is obtained by the **Viterbi algorithm**. \n",
    "\n",
    "For this part of the assignment, pick a path in advance and record the set of measurements the robot would take along the road. Do not forget to include the possibility of getting some incorrect measurements in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_likely_sequence(E, O, S, T, X0):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function finds the most likely sequence of states given a sequence of measurements using the \n",
    "    Viterbi algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - E (list): List of binary measurements obtained at each time step.\n",
    "    - O (dict): Dictionary of observation matrices for different binary measurements.\n",
    "    - S (list): List of state names or indices.\n",
    "    - T (numpy.ndarray): Transition matrix representing the probabilities of transitioning between states.\n",
    "    - X0 (numpy.ndarray): Initial probability distribution over states.\n",
    "\n",
    "    Returns:\n",
    "    - best_sequence (list): Most likely sequence of states corresponding to the given sequence of measurements.\n",
    "    \"\"\"\n",
    "    \n",
    "    sequences = np.zeros((T.shape[0], len(E)))\n",
    "    states = np.zeros((T.shape[0], len(E)))\n",
    "    ones = np.ones((T.shape[0], T.shape[0]))\n",
    "    sequences[:, 0] = (O[E[0]] @ X0).reshape((T.shape[0],))\n",
    "    message = sequences[:, 0].reshape((T.shape[0], 1))\n",
    "    \n",
    "    for i, evidence in enumerate(E[1:]):\n",
    "        message = (T @ O[evidence]) * (message * ones)\n",
    "        states[:, i+1] = np.argmax(message, axis=0).reshape((T.shape[0],))\n",
    "        message = np.max(message, axis=0).reshape((T.shape[0], 1))\n",
    "        sequences[:, i+1] = message.reshape((T.shape[0],))\n",
    "        \n",
    "    states = states.astype('int32')\n",
    "    s = np.argmax(sequences[:, -1], axis=0)\n",
    "    best_sequence = [S[s]]\n",
    "    \n",
    "    for i in range(len(E)-1, 0, -1):\n",
    "        s = states[s, i]\n",
    "        best_sequence.append(S[s])\n",
    "        \n",
    "    best_sequence = best_sequence[::-1] \n",
    "    \n",
    "    return best_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = most_likely_sequence(E, O, S, T, X0)\n",
    "sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the sequence of states obtained after calling the `most_likely_sequence` function with the actual path followed by the robot. Ignoring the initial position of the robot, i.e. the initial state, all the locations stored in the variable `sequence` should be the same as those stored in the variable `path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization purposes, define a vector of 42 components in which the entry associated to a state that belongs to the most likely sequence is set to one, otherwise, set the entry to zero. Call the `view_heatmap` function, which should receive the vector that you just defined as an input, and obtain the corresponding heatmap. The shown path should be the sequence of locations that the robot occupied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You will have to write some code here for computing your vector of zeros and ones. Store this information\n",
    "as \"vector\".\n",
    "\"\"\"\n",
    "\n",
    "vector = np.zeros((42,1))\n",
    "\n",
    "\"INSERT YOUR CODE HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_heatmap(vector, S)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
